{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WAW ML5 Tutorial - Hyperparameter Optimization - Part 2\n",
    "\n",
    "<img src='https://raw.githubusercontent.com/DLR-SC/Hyperparameter_tutorial/master/img/WAW_Tutorial_Title.png' width=500px>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import talos\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Overview\n",
    "\n",
    "The aim of the 2nd tutorial is the following:\n",
    "\n",
    "* Introduction of Talos\n",
    "* Use Talos for machine-assisted hyperparameter optimization of the Boston house price problem (1st Jupyter notebook)\n",
    "* Give general guidelines for hyperparamter optimization"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introduction of Talos <a name=\"one\"></a> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Start (iteration 0) with the original Keras code \n",
    "\n",
    "We first start with the code that we have already used in the first notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "from keras.datasets import boston_housing\n",
    "\n",
    "# load the data\n",
    "(train_data, train_targets), (test_data, test_targets) =  boston_housing.load_data()\n",
    "\n",
    "# data normalization\n",
    "mean = train_data.mean(axis=0)\n",
    "train_data -= mean\n",
    "std = train_data.std(axis=0)\n",
    "train_data /= std\n",
    "\n",
    "test_data -= mean\n",
    "test_data /= std"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Model preparation\n",
    "\n",
    "Talos works with any Keras model, without changing the structure of the model in any way.  \n",
    "The only difference in the Keras model is that a parameter is not set explicitly as before, e.g.\n",
    "\n",
    "<pre><code> model.add(layers.Dense(32, activation='relu'))    </code></pre>\n",
    "\n",
    "but instead taken from a dictionary, e.g.\n",
    "\n",
    "<pre><code>\n",
    "params = {'number_of_neurons' : [4, 6, 7, 8], 'activation' : ['relu'] }\n",
    "\n",
    "model.add(layers.Dense(params['number_of_neurons'], activation=params['activation']))    \n",
    "</code></pre>\n",
    "\n",
    "Afterwards, this dictionary and the model will be passed to Talos. In the dictionary we have \n",
    "three different ways to input values:\n",
    "\n",
    "- as stepped ranges (min, max, steps)\n",
    "- as multiple values [in a list]\n",
    "- as a single value [in a list]\n",
    "\n",
    "For values we don't want to use, it's ok to set it as None.\n",
    "\n",
    "NOTE: at this point you have to import from Keras the optimizer, activations, and losses you want to scan for."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Tasks ## \n",
    "__Excercise 1:__\n",
    " - Create a Python dictionary that contains at least the following entries:\n",
    "    * 'number_of_layers' : 1, 2\n",
    "    * 'number_of_neurons' : 8, 16, 32, 64\n",
    "    * 'dropout_value' : None, 0.1, 0.2\n",
    "    * 'optimizer' : 'Adam', 'rmsprop'\n",
    "    * 'batch_size': 1, 2, 4, 8 \n",
    "    * 'epoch_number' : 10, 20, 40, 80\n",
    "    * anything that you want to modify further (e.g. learning_rate, activation_function, loss_function, ...)\n",
    " - What is the number of different hyperparameter configurations that is considered?"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# parameter dictionary\n",
    "param = {'number_of_layers' : [1, 2],\n",
    "         'number_of_neurons' : [8, 16, 32, 64],\n",
    "         'epoch_number' : [10, 20, 40, 80],\n",
    "         'dropout_value' : [None, 0.1, 0.2],\n",
    "         'optimizer' : ['Adam', 'rmsprop'],\n",
    "         'batch_size' : [1, 2, 4, 8]}\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Tasks ## \n",
    "__Excercise 2:__\n",
    " - Modify your original Keras model (Jupyter notebook 1) such that it uses uses the values from a \n",
    " dictionary 'p'."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "\n",
    "def build_better_model(train_data, train_targets, val_data, val_targets, p):\n",
    "    model = models.Sequential()\n",
    "    \n",
    "    # replace the hyperparameter inputs with references to dictionary p \n",
    "    model.add(layers.Dense(p['number_of_neurons'], activation='relu',\n",
    "                           input_shape=(train_data.shape[1],)))\n",
    "    \n",
    "    if p['number_of_layers'] >= 2:\n",
    "        model.add(layers.Dense(p['number_of_neurons'], activation='relu'))\n",
    "    \n",
    "    if p['dropout_value'] is not None:\n",
    "        model.add(layers.Dropout(p['dropout_value']))\n",
    "        \n",
    "    model.add(layers.Dense(1))\n",
    "    model.compile(optimizer='Adam', loss='mse', metrics=['mae'])\n",
    "    \n",
    "    # make sure history object is returned by model.fit()\n",
    "    history = model.fit(train_data, train_targets, epochs=p['epoch_number'], batch_size=p['batch_size'], verbose=0)\n",
    "    \n",
    "    return history, model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2. Use Talos for hyperparameter optimization <a name=\"two\"></a> \n",
    "\n",
    "This part is quite simple. The Talos experiment just uses the <code> Scan()<\\code> command. In the following,\n",
    "we will investigate different arguments for this routine. However, it there are only four necessary arguments\n",
    "that are required:\n",
    "* train_data (often known as 'x')\n",
    "* train_targets (often known as 'y')\n",
    "* params (the dictionary 'param' that we have created before)\n",
    "* model (the 'build_model' that we also have created before)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "text": [
      "\r  0%|          | 0/10 [00:00<?, ?it/s]",
      "\r 10%|█         | 1/10 [00:01<00:17,  1.93s/it]",
      "\r 20%|██        | 2/10 [00:08<00:27,  3.43s/it]",
      "\r 30%|███       | 3/10 [00:11<00:22,  3.14s/it]",
      "\r 40%|████      | 4/10 [00:17<00:24,  4.11s/it]",
      "\r 50%|█████     | 5/10 [00:19<00:16,  3.36s/it]",
      "\r 60%|██████    | 6/10 [00:21<00:11,  2.87s/it]",
      "\r 70%|███████   | 7/10 [00:24<00:09,  3.07s/it]",
      "\r 80%|████████  | 8/10 [00:26<00:05,  2.86s/it]",
      "\r 90%|█████████ | 9/10 [00:30<00:03,  3.14s/it]",
      "\r100%|██████████| 10/10 [00:32<00:00,  2.71s/it]",
      "\r100%|██████████| 10/10 [00:32<00:00,  3.24s/it]",
      "\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "scan_object = talos.Scan(x=train_data,\n",
    "                         y=train_targets,\n",
    "                         model=build_better_model,\n",
    "                         experiment_name='find_optimal_params',\n",
    "                         params=param,\n",
    "                         round_limit=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "If all different parameter configurations from the dictionary are used, the routine <code> Scan()</code> has to\n",
    "evaluate 768 different models. Depending on the neural network architecture and the number of training samples,\n",
    "this can be very time consuming.\n",
    "\n",
    "As a solution, Talos offers several routines to limit the number of model configurations that is evaluated. Two useful\n",
    "commands of <code> Scan()</code> for this purpose are:\n",
    "\n",
    "* <code> round_limit=10</code> which limits the number of model evaluations to the specified integer value (e.g. \n",
    "10 model evaluations in this example).\n",
    "* <code> fraction_limit = 0.1</code> specifies the fraction of `params` that will be tested  (e.g. 10% of the \n",
    "configurations in this example).   "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Access the results through the <code>Scan</code> object "
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Using <code> round_limit=10</code> we have actually investigated only ten parameter configurations (since the time\n",
    "for this tutorial is limited). But how do I get the ten configurations that have been used and what is their\n",
    "performance?\n",
    "\n",
    "For this purpose, the results of the scan object can be directly accessed:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "   round_epochs        loss        mae  batch_size  dropout_value  \\\n0            10  173.413228  11.236574           8            0.1   \n1            40   14.938728   2.862601           2            0.2   \n2            10   24.192568   3.609028           2            0.1   \n3            80   33.016906   4.234593           4            0.2   \n4            20  112.600002   8.253620           8            0.2   \n5            10   23.136458   3.445873           4            0.1   \n6            10   26.904475   3.739406           1            0.1   \n7            20   27.768293   3.840090           4            0.1   \n8            10   42.682594   4.920127           1            0.2   \n9            20   40.555902   4.778998           8            0.1   \n\n   epoch_number  number_of_layers  number_of_neurons optimizer  \n0            10                 1                 32      Adam  \n1            40                 2                 32   rmsprop  \n2            10                 2                 16   rmsprop  \n3            80                 1                 16   rmsprop  \n4            20                 1                  8   rmsprop  \n5            10                 2                 32      Adam  \n6            10                 1                 16   rmsprop  \n7            20                 1                 32      Adam  \n8            10                 2                  8      Adam  \n9            20                 2                  8   rmsprop  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>round_epochs</th>\n      <th>loss</th>\n      <th>mae</th>\n      <th>batch_size</th>\n      <th>dropout_value</th>\n      <th>epoch_number</th>\n      <th>number_of_layers</th>\n      <th>number_of_neurons</th>\n      <th>optimizer</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>10</td>\n      <td>173.413228</td>\n      <td>11.236574</td>\n      <td>8</td>\n      <td>0.1</td>\n      <td>10</td>\n      <td>1</td>\n      <td>32</td>\n      <td>Adam</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>40</td>\n      <td>14.938728</td>\n      <td>2.862601</td>\n      <td>2</td>\n      <td>0.2</td>\n      <td>40</td>\n      <td>2</td>\n      <td>32</td>\n      <td>rmsprop</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>10</td>\n      <td>24.192568</td>\n      <td>3.609028</td>\n      <td>2</td>\n      <td>0.1</td>\n      <td>10</td>\n      <td>2</td>\n      <td>16</td>\n      <td>rmsprop</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>80</td>\n      <td>33.016906</td>\n      <td>4.234593</td>\n      <td>4</td>\n      <td>0.2</td>\n      <td>80</td>\n      <td>1</td>\n      <td>16</td>\n      <td>rmsprop</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>20</td>\n      <td>112.600002</td>\n      <td>8.253620</td>\n      <td>8</td>\n      <td>0.2</td>\n      <td>20</td>\n      <td>1</td>\n      <td>8</td>\n      <td>rmsprop</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>10</td>\n      <td>23.136458</td>\n      <td>3.445873</td>\n      <td>4</td>\n      <td>0.1</td>\n      <td>10</td>\n      <td>2</td>\n      <td>32</td>\n      <td>Adam</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>10</td>\n      <td>26.904475</td>\n      <td>3.739406</td>\n      <td>1</td>\n      <td>0.1</td>\n      <td>10</td>\n      <td>1</td>\n      <td>16</td>\n      <td>rmsprop</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>20</td>\n      <td>27.768293</td>\n      <td>3.840090</td>\n      <td>4</td>\n      <td>0.1</td>\n      <td>20</td>\n      <td>1</td>\n      <td>32</td>\n      <td>Adam</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>10</td>\n      <td>42.682594</td>\n      <td>4.920127</td>\n      <td>1</td>\n      <td>0.2</td>\n      <td>10</td>\n      <td>2</td>\n      <td>8</td>\n      <td>Adam</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>20</td>\n      <td>40.555902</td>\n      <td>4.778998</td>\n      <td>8</td>\n      <td>0.1</td>\n      <td>20</td>\n      <td>2</td>\n      <td>8</td>\n      <td>rmsprop</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 6
    }
   ],
   "source": [
    "# accessing the results data frame\n",
    "scan_object.data\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The output on my local computer is (the results should differ on your machine since you \n",
    "consider ten other parameter configurations which we will explain later on)\n",
    "\n",
    "<img src='https://raw.githubusercontent.com/DLR-SC/Hyperparameter_tutorial/master/img/talos_scan_output.png' \n",
    "width=1000px>\n",
    "\n",
    "There are several hyperparameter configurations with a mean average error (mae) in the range 2-3.\n",
    "Since the number of training samples is only 400, the result of the mean average error \n",
    "have a high variance and should not be overestimated. Nevertheless, the we already obtain a certain \n",
    "intuition on the size of some of the hyperparameters (e.g. 10 epochs is certainly not\n",
    " enough since 'mae' becomes large then).\n",
    " "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "You already noticed that your results differ from mine. This is due to the usage of a 'random search'\n",
    "strategy in Talos. More information on the search strategy are given \n",
    "in the summary details using <code>scan_object.details</code>.  "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "experiment_name        find_optimal_params\nrandom_method             uniform_mersenne\nreduction_method                      None\nreduction_interval                      50\nreduction_window                        20\nreduction_threshold                    0.2\nreduction_metric                   val_acc\ncomplete_time               11/19/19/11:01\nx_shape                          (404, 13)\ny_shape                             (404,)\ndtype: object"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 7
    }
   ],
   "source": [
    "# access the summary details\n",
    "scan_object.details\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "From the 768 possible hyperparameter configurations Talos considers a random subset\n",
    "of ten configurations (due to <code>round_limit=10</code>). This random subset \n",
    "is chosen with a 'Mersenne Twister' pseudorandom number generator. Other possible\n",
    "random choices are e.g. 'Halton' or 'Sobol' quasi Monte Carlo sequences. \n",
    "\n",
    "Note: If there is no parameter such as  <code> round_limit=10</code> or\n",
    "<code> fraction_limit = 0.1</code> the default optimization strategy \n",
    "is called 'grid search'. This means that all hyperparameter permutations in \n",
    "a given dictionary are processed. In most cases, this is not recommended\n",
    "for anything but very small permutation spaces. \n",
    "Therefore, better use a 'random search' routine."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition to statistics and meta-data related with the Scan, the used data (x and y) \n",
    "together with the saved model and model weights for each hyperparameter permutation is stored in the Scan object. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "[array([[-8.38897407e-01, -1.43938139e-01,  1.11391522e-01,\n         -1.09193353e-02,  2.58457959e-01,  2.17029408e-01,\n         -2.04411387e-01, -8.21907043e-01, -2.64130056e-01,\n         -6.01866804e-02, -7.31536001e-02, -1.39986232e-01,\n          4.16413635e-01, -5.20827956e-02,  5.98771423e-02,\n          4.12954122e-01,  2.31539115e-01,  1.11565955e-01,\n          2.63870001e-01, -2.02329814e-01, -2.50781149e-01,\n          2.32718915e-01, -5.56486659e-02,  1.35042012e-01,\n         -3.68533343e-01,  7.01688975e-02,  2.37694308e-01,\n         -2.54949778e-01, -2.98739910e-01, -2.88264781e-01,\n          8.69323611e-02,  2.34808996e-01],\n        [-1.24940433e-01, -1.07590645e-03, -2.83617735e-01,\n          2.80249089e-01,  1.20290406e-01,  2.57741481e-01,\n         -2.87064195e-01, -1.31497920e-01, -3.32656838e-02,\n         -2.66632348e-01,  2.29115617e-02,  1.90930948e-01,\n         -1.74275011e-01, -2.16409728e-01,  2.39052877e-01,\n          1.47082329e-01, -1.37673736e-01, -1.60397105e-02,\n          2.75386006e-01,  3.25601455e-03, -2.71030992e-01,\n          1.56499863e-01, -2.94379950e-01, -1.73610672e-01,\n          9.74762291e-02, -2.42578551e-01, -2.63779700e-01,\n          2.87162125e-01, -2.32578546e-01, -3.08826476e-01,\n         -1.82337999e-01,  3.16767991e-01],\n        [-3.40563320e-02, -3.63274306e-01,  1.50433257e-01,\n         -4.16490734e-01,  2.25619927e-01,  1.77123129e-01,\n         -1.50695160e-01, -3.36541682e-01,  3.04488778e-01,\n          1.89283624e-01, -1.01901643e-01, -3.13473284e-01,\n          1.29849315e-01, -3.77692670e-01,  9.45496664e-04,\n         -1.20469898e-01, -1.48735613e-01,  1.81677654e-01,\n          2.34787971e-01, -6.56715687e-03, -3.49715024e-01,\n          3.32425922e-01,  2.24657342e-01, -2.73868591e-01,\n          3.71968657e-01,  4.23038483e-01, -2.37158239e-01,\n         -5.19266903e-01,  4.24811333e-01,  2.75636613e-01,\n         -2.75451422e-01, -1.61499783e-01],\n        [-1.58188492e-01, -1.40171677e-01,  9.55607295e-02,\n          1.72870100e-01,  3.89005244e-01,  1.62314683e-01,\n         -5.59548736e-01, -5.15336692e-01,  3.00981849e-01,\n         -4.92547393e-01, -1.12601906e-01, -1.58758871e-02,\n         -2.73515105e-01,  2.47029215e-01,  1.70477077e-01,\n         -1.98321659e-02, -2.42367551e-01, -1.53909460e-01,\n          1.44665748e-01,  1.05595018e-03, -4.34450775e-01,\n         -9.80469733e-02,  1.15016997e-01,  4.20251578e-01,\n         -1.18518963e-01,  2.53348202e-01,  1.19245984e-01,\n         -1.95111424e-01, -2.08052114e-01,  3.42355281e-01,\n          3.41444202e-02,  3.66936661e-02],\n        [ 3.27681065e-01, -1.85070604e-01, -5.42001188e-01,\n          1.89317483e-02, -4.56118703e-01, -3.87366004e-02,\n          1.75535783e-01,  5.32265425e-01, -2.51903921e-01,\n          1.81747511e-01, -1.06985003e-01,  4.01794389e-02,\n         -5.77496588e-01, -1.61238387e-01,  7.67500639e-01,\n          2.96662718e-01, -3.55913192e-01, -2.72430718e-01,\n         -4.87444341e-01,  1.00701459e-01,  6.51932955e-02,\n          6.41808569e-01, -9.77623910e-02, -5.77814341e-01,\n          2.00919539e-01, -3.08446169e-01, -3.24818730e-01,\n         -4.10886317e-01,  4.44095999e-01, -2.87076861e-01,\n         -5.03965318e-02, -3.34461540e-01],\n        [ 4.75281537e-01,  2.35690847e-02, -6.03100620e-02,\n         -1.25725850e-01,  4.04311687e-01, -3.84255916e-01,\n         -1.29691586e-01,  3.85261804e-01,  2.19490871e-01,\n          1.33519039e-01, -1.47145791e-02, -8.43037367e-02,\n         -6.90341890e-02, -1.76946118e-01,  1.09626614e-01,\n         -4.09026116e-01,  3.18371981e-01, -1.07538976e-01,\n          4.82594103e-01, -4.65258479e-01,  3.42639148e-01,\n          5.30234933e-01, -1.81965679e-01, -1.52415380e-01,\n          6.36510730e-01,  3.04709971e-01, -4.04569298e-01,\n          1.32891670e-01, -1.03460215e-01, -2.64587760e-01,\n         -1.28817230e-01, -1.06804483e-01],\n        [-3.14091563e-01, -1.75680429e-01,  2.27289513e-01,\n         -6.41884357e-02, -5.46021163e-02,  2.67793804e-01,\n          1.27418771e-01, -6.98214918e-02,  5.22442646e-02,\n         -3.74386847e-01, -1.21798180e-01, -5.94173092e-03,\n          1.41752690e-01, -1.87521264e-01,  4.77723747e-01,\n         -5.12066185e-01, -2.36732796e-01, -2.06271991e-01,\n          2.72235721e-01,  8.65015294e-03,  1.40670165e-02,\n         -2.84492999e-01,  1.89530939e-01,  1.33011535e-01,\n         -3.44699502e-01, -4.78256047e-02, -1.35049760e-01,\n         -3.84787410e-01,  2.68881023e-01,  2.63686717e-01,\n         -3.17887127e-01, -3.91206712e-01],\n        [ 7.69681355e-05,  1.66511253e-01, -1.87855795e-01,\n          2.54639536e-01,  1.46840345e-02, -4.80955802e-02,\n          2.31181100e-01,  2.01722831e-01, -5.95266998e-01,\n         -1.68049172e-01, -4.16856915e-01, -1.94349185e-01,\n         -1.94954962e-01, -2.93171227e-01,  8.24688524e-02,\n          8.24329779e-02,  7.51877278e-02, -3.33368480e-01,\n         -1.70316808e-02, -1.91573068e-01,  2.10216001e-01,\n         -2.49552913e-02, -5.05997300e-01, -5.10581851e-01,\n         -1.82313591e-01,  2.42723122e-01, -5.07195830e-01,\n         -1.35885701e-01,  5.29080033e-01, -5.10349870e-01,\n         -3.11565995e-01, -3.33602160e-01],\n        [ 1.15487710e-01, -7.17724934e-02,  2.66784459e-01,\n          9.90467072e-02,  3.50995734e-02,  3.17079782e-01,\n         -5.83890416e-02,  2.31607273e-01,  3.45502228e-01,\n         -1.90206751e-01, -1.44458324e-01,  2.83038378e-01,\n          3.70714396e-01,  8.54259357e-02, -2.80445516e-01,\n          1.35765895e-01,  4.45909560e-01,  2.66944557e-01,\n          3.48156333e-01,  1.91326678e-01,  1.21575389e-02,\n         -1.82807326e-01,  3.23228627e-01, -1.05190445e-02,\n         -2.20800519e-01,  4.33749944e-01,  1.20871283e-01,\n          6.43985793e-02,  2.58599669e-02, -3.66974145e-01,\n          3.50211471e-01,  3.61283422e-01],\n        [ 1.92781091e-01, -3.57042819e-01,  1.39497295e-01,\n          4.29961890e-01,  5.27929105e-02, -1.15445428e-01,\n          1.49054915e-01, -2.94778973e-01,  6.99394122e-02,\n         -3.08513701e-01, -1.71599388e-01,  5.87433241e-02,\n          2.37479359e-01, -3.34654421e-01,  1.92559939e-02,\n         -1.65464267e-01,  3.54094446e-01, -3.30346286e-01,\n          8.02133325e-03, -7.83396885e-02, -1.18365847e-01,\n          1.96501970e-01, -8.04564655e-02, -1.40040834e-02,\n         -4.93160397e-01, -3.28990407e-02,  9.37793255e-02,\n          4.45693471e-02, -1.36033908e-01,  5.44422641e-02,\n         -2.82090515e-01,  4.40097265e-02],\n        [-9.36045796e-02, -9.55314338e-02,  2.37267196e-01,\n          4.28560942e-01, -2.85875678e-01,  2.68878043e-01,\n         -1.19086213e-01, -7.37015083e-02, -4.46884722e-01,\n          4.12098095e-02, -5.01860678e-01,  1.57230068e-02,\n         -3.56421232e-01, -2.24863812e-01, -2.57608503e-01,\n         -1.18161827e-01, -8.01241919e-02, -2.87862867e-01,\n          1.62573382e-01,  2.65316993e-01, -5.64549983e-01,\n         -3.13730150e-01, -4.08507615e-01, -2.47607112e-01,\n          2.82174587e-01, -3.06173414e-02,  5.17971218e-01,\n          2.59522349e-01, -4.23186928e-01,  1.25441656e-01,\n          3.34271222e-01,  2.01815128e-01],\n        [-4.83444259e-02,  7.72679448e-02, -1.42539799e-01,\n         -3.77566903e-03,  1.58478484e-01, -1.90139294e-01,\n         -9.85979810e-02,  2.36749843e-01,  2.35894248e-01,\n          4.30018365e-01, -1.15088157e-01,  8.72349292e-02,\n          2.36259997e-01, -1.73604876e-01,  1.67493984e-01,\n         -2.55502105e-01, -1.14381917e-01, -7.31879612e-03,\n          1.17389195e-01, -9.31731015e-02,  4.93158460e-01,\n          1.00276172e-01,  1.95438579e-01,  1.80789959e-02,\n         -3.28017101e-02,  2.13873789e-01,  2.80154943e-01,\n         -1.74972024e-02, -1.30647808e-01, -6.88659726e-03,\n          7.84040838e-02,  1.44674703e-01],\n        [-3.90844494e-02,  5.79495549e-01, -4.53230053e-01,\n         -5.25565565e-01,  9.52380672e-02,  8.87918752e-03,\n          3.08543265e-01, -7.41727799e-02, -3.14015478e-01,\n          2.06118673e-01,  3.17994833e-01, -1.99973106e-01,\n          2.21722335e-01,  2.77461410e-01,  8.66111517e-01,\n         -3.18725973e-01, -2.09120601e-01,  1.13721415e-01,\n         -4.83060777e-01,  4.98823553e-01, -1.67767238e-02,\n         -5.84775098e-02,  1.65555909e-01, -3.59346598e-01,\n         -1.87509358e-01, -5.40816963e-01, -2.66944636e-02,\n          2.71608651e-01, -6.79768696e-02, -3.15120608e-01,\n          3.65265571e-02, -4.62519348e-01]], dtype=float32),\n array([ 0.17220186,  0.26380596,  0.11486444, -0.03245797,  0.09758783,\n        -0.05613348,  0.32867515,  0.4542739 ,  0.20221448,  0.26841813,\n         0.04778967,  0.03893034, -0.14873804,  0.05098663, -0.12724216,\n        -0.14061925, -0.09886685,  0.05937528,  0.13177533,  0.49662787,\n         0.35938558, -0.26767564,  0.09502161,  0.35295492,  0.08880909,\n         0.19480628,  0.05850316,  0.21647412,  0.13951446,  0.04122077,\n         0.12372141,  0.00409046], dtype=float32),\n array([[ 0.2512441 , -0.05707823,  0.10596129, ...,  0.47102445,\n         -0.0791672 , -0.09659043],\n        [ 0.21849267,  0.37910214, -0.04409702, ...,  0.39852563,\n          0.34623653, -0.24124397],\n        [ 0.2810845 ,  0.08094993,  0.00101326, ..., -0.13494436,\n          0.3002604 , -0.24120995],\n        ...,\n        [ 0.30932635,  0.32392097,  0.13690107, ..., -0.13874611,\n          0.3786297 , -0.08386455],\n        [ 0.04927675, -0.0716415 ,  0.20969325, ..., -0.08688017,\n          0.00406479,  0.05598047],\n        [ 0.1548488 ,  0.3562979 ,  0.43040782, ...,  0.37837663,\n          0.2758052 , -0.34345275]], dtype=float32),\n array([ 0.4549195 ,  0.36825517,  0.27584556,  0.39780354, -0.03260187,\n         0.35018963,  0.31720966,  0.29588246,  0.28491518,  0.21125612,\n         0.26888356,  0.39646724,  0.3756515 , -0.11983629,  0.3766964 ,\n         0.38165256, -0.01821574,  0.2917557 ,  0.07217783, -0.03788698,\n         0.2746237 ,  0.37335882,  0.29665473,  0.19477518,  0.3214527 ,\n         0.33210075,  0.27370927,  0.34776548,  0.43679744,  0.43861914,\n         0.19028257, -0.16427408], dtype=float32),\n array([[ 0.32296842],\n        [ 0.3146912 ],\n        [ 0.5958557 ],\n        [ 0.29212773],\n        [-0.65416825],\n        [ 0.3738818 ],\n        [ 0.46020713],\n        [ 0.43895075],\n        [ 0.32855457],\n        [ 0.34995675],\n        [ 0.38211378],\n        [ 0.29224992],\n        [ 0.36609256],\n        [-0.51601094],\n        [ 0.3969985 ],\n        [ 0.2838303 ],\n        [-0.27495235],\n        [ 0.513852  ],\n        [ 0.31806302],\n        [-0.0189339 ],\n        [ 0.4861372 ],\n        [ 0.33192313],\n        [ 0.49193236],\n        [ 0.6386999 ],\n        [ 0.43655878],\n        [ 0.2708612 ],\n        [ 0.38509136],\n        [ 0.4143176 ],\n        [ 0.25413823],\n        [ 0.2503321 ],\n        [ 0.56012565],\n        [-0.25290522]], dtype=float32),\n array([1.6063222], dtype=float32)]"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 13
    }
   ],
   "source": [
    "# accessing the saved models which returns a list of models\n",
    "scan_object.saved_models\n",
    "\n",
    "# accessing the saved weights for models which returns a list of weights\n",
    "model_weights = scan_object.saved_weights\n",
    "\n",
    "# weights of first model \n",
    "model_weights[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Scan object can be further used, and is required, as input for Predict(), Evaluate(), and Deploy(). \n",
    "More about this in the corresponding sections below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysing the Scan results with <code>Reporting()</code> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the Scan process, the results are stored round-by-round in the corresponding experiment log which is a .csv file stored in the \n",
    "present working directory (which is './find_optimal_params' our case). The Reporting() \n",
    "accepts as its source either a file name, or the Scan object. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# use Scan object as input\n",
    "analyze_object = talos.Analyze(scan_object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "10"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 9
    }
   ],
   "source": [
    "# get the number of rounds in the Scan\n",
    "analyze_object.rounds()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "2.8626010417938232"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 10
    }
   ],
   "source": [
    "# get the lowest result for any metric (if lower is better)\n",
    "analyze_object.low('mae')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Next, we want to obtain the parameters of our best n=3 parameter runs. For this\n",
    "purpose we use <code> best_params</code>. It is alluring to consider the best \n",
    "result only (i.e. n=1 in the following cell) but keep in mind that due to the high\n",
    "variance in the result, a sequence of more models should be considered.\n",
    "\n",
    "The signature of <code> best_params</code> is the following:\n",
    "* The first argument (here 'mae') is the metric that is considered.\n",
    "* The second argument is a list of metrics / loss functions that is not required here\n",
    "* The third argument gives the 'n' best results\n",
    "* Fourth argument: ascending | bool | Set to True when `metric` is to be minimized eg. loss or mae"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[0.2, 2, 2, 32, 40, 'rmsprop', 40, 0],\n       [0.1, 4, 2, 32, 10, 'Adam', 10, 1],\n       [0.1, 2, 2, 16, 10, 'rmsprop', 10, 2]], dtype=object)"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 11
    }
   ],
   "source": [
    "# get the best n=3 paramaters\n",
    "analyze_object.best_params('mae', ['loss'], n=3, ascending=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "It is very important to determine which of your hyperparameter has the largest impact on \n",
    "your performance metric. These are the parameters that should be further investigated. \n",
    "\n",
    "One solution to achive this is to compute the linear correlation between your performance metric\n",
    "'mae' and your hyperparamters. The correlation coefficient is +1 in the case of a perfect direct\n",
    "(increasing) linear relationship, -1 in the case of a perfect decreasing (inverse) linear \n",
    "relationship and some values in (-1, 1) otherwise (indicating the degree of linear dependance\n",
    "between the variables).\n",
    "\n",
    "We employ <code> correlate()</code> for computing the correlation"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "batch_size           0.710765\ndropout_value       -0.007994\nepoch_number        -0.212363\nnumber_of_layers    -0.469804\nnumber_of_neurons   -0.020119\nName: mae, dtype: float64"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 12
    }
   ],
   "source": [
    "# get correlation for hyperparameters against a performance metric such as 'mae' (we exclude 'loss' since \n",
    "# this is not a hyperparameter)\n",
    "analyze_object.correlate('mae', ['loss', 'round_epochs'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Since you have only then different hyperparameter runs, the output is almost random. However, in practice \n",
    "with hundreds or thousand of different configurations the result is valuable to find the important hyperparameters.\n",
    "\n",
    "<img src='https://raw.githubusercontent.com/DLR-SC/Hyperparameter_tutorial/master/img/talos_correlate.png' \n",
    "width=240px>\n",
    "\n",
    "so (im my special case) 'epoch_number' and 'number_of_neurons' have the strongest inverse effect on 'mae'\n",
    "(i.e. something like 'more epochs leads to a lower mean average error'). The 'batch_size' seems to be less important. "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also plot a heatmap of this correlation using <code> plot_corr()</code>:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stderr",
     "text": [
      "findfont: Font family ['Verdana'] not found. Falling back to DejaVu Sans.\n"
     ],
     "output_type": "stream"
    },
    {
     "data": {
      "text/plain": "<Figure size 576x576 with 2 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# heatmap correlation\n",
    "analyze_object.plot_corr('mae', ['loss', 'round_epochs'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The correlation between variables in one viable way to find the most important\n",
    "hyperparameters. A different approach is given by <code> plot_bars()</code>.\n",
    "Using this function, the metric 'mae' is plotted for different values of the \n",
    "hyperparameters 'number_of_neurons', 'number_of_layers' and 'epoch_number'. As mentioned\n",
    "before, 'mae' seems to decrease for larger values of these hyperparameters (in the\n",
    "specified region of the dictionary).\n",
    "\n",
    "The bar grid has error bars if there is more than one result for the specified\n",
    "three hyperparameters 'number_of_neurons', 'epoch_number' and 'number_of_layers'. "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 1253.38x288 with 2 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# a four dimensional bar grid\n",
    "analyze_object.plot_bars('number_of_neurons','mae', 'epoch_number', 'number_of_layers')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "My output plot is\n",
    "\n",
    "<img src='https://raw.githubusercontent.com/DLR-SC/Hyperparameter_tutorial/master/img/talos_bar.png' \n",
    "width=1300px>"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Tasks ## \n",
    "__Excercise 3:__\n",
    " - Apply the described process to your Talos output. Im more details:\n",
    "    * Find the hyperparameters that have the strongest effect on the performance metric.\n",
    "    * Create a 2nd hyperparameter dictionary that further investigates the important hyperparameters\n",
    "    * Use <code> Scan() </code> to investigate the 2nd dictionary in more detail \n",
    "    (use larger values for round_limit than 10).\n",
    "    * Try to find a close-to-optimal model for this specific regression problem. "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "# your new hyperparameter dictionary\n",
    "param2 = {'number_of_layers' : [1, 2],\n",
    "         'number_of_neurons' : [8, 16, 32, 64],\n",
    "         'epoch_number' : [10, 20, 40, 80],\n",
    "         'dropout_value' : [0.1],\n",
    "         'optimizer' : ['Adam'],\n",
    "         'batch_size' : [2]}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stderr",
     "text": [
      "\r  0%|          | 0/30 [00:00<?, ?it/s]",
      "\r  3%|▎         | 1/30 [00:08<03:57,  8.19s/it]",
      "\r  7%|▋         | 2/30 [00:24<04:58, 10.67s/it]",
      "\r 10%|█         | 3/30 [00:34<04:39, 10.35s/it]",
      "\r 13%|█▎        | 4/30 [00:37<03:32,  8.19s/it]",
      "\r 17%|█▋        | 5/30 [00:55<04:36, 11.08s/it]",
      "\r 20%|██        | 6/30 [01:00<03:42,  9.25s/it]",
      "\r 23%|██▎       | 7/30 [01:02<02:46,  7.22s/it]",
      "\r 27%|██▋       | 8/30 [01:15<03:13,  8.80s/it]",
      "\r 30%|███       | 9/30 [01:17<02:25,  6.94s/it]",
      "\r 33%|███▎      | 10/30 [01:21<01:57,  5.88s/it]",
      "\r 37%|███▋      | 11/30 [01:28<01:57,  6.16s/it]",
      "\r 40%|████      | 12/30 [01:31<01:37,  5.42s/it]",
      "\r 43%|████▎     | 13/30 [01:38<01:39,  5.88s/it]",
      "\r 47%|████▋     | 14/30 [01:45<01:37,  6.12s/it]",
      "\r 50%|█████     | 15/30 [01:58<02:04,  8.33s/it]",
      "\r 53%|█████▎    | 16/30 [02:00<01:30,  6.48s/it]",
      "\r 57%|█████▋    | 17/30 [02:04<01:13,  5.68s/it]",
      "\r 60%|██████    | 18/30 [02:07<00:56,  4.68s/it]",
      "\r 63%|██████▎   | 19/30 [02:14<00:58,  5.35s/it]",
      "\r 67%|██████▋   | 20/30 [02:27<01:18,  7.82s/it]",
      "\r 70%|███████   | 21/30 [02:36<01:12,  8.06s/it]",
      "\r 73%|███████▎  | 22/30 [02:48<01:15,  9.46s/it]",
      "\r 77%|███████▋  | 23/30 [02:55<01:00,  8.58s/it]",
      "\r 80%|████████  | 24/30 [02:58<00:40,  6.79s/it]",
      "\r 83%|████████▎ | 25/30 [03:02<00:29,  5.94s/it]",
      "\r 87%|████████▋ | 26/30 [03:06<00:22,  5.60s/it]",
      "\r 90%|█████████ | 27/30 [03:11<00:16,  5.38s/it]",
      "\r 93%|█████████▎| 28/30 [03:26<00:16,  8.29s/it]",
      "\r 97%|█████████▋| 29/30 [03:29<00:06,  6.54s/it]",
      "\r100%|██████████| 30/30 [03:33<00:00,  5.73s/it]",
      "\r100%|██████████| 30/30 [03:33<00:00,  7.10s/it]",
      "\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "scan_object2 = talos.Scan(x=train_data,\n",
    "                         y=train_targets,\n",
    "                         model=build_better_model,\n",
    "                         experiment_name='find_optimal_params',\n",
    "                         params=param2,\n",
    "                         round_limit=30)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [
    {
     "data": {
      "text/plain": "    round_epochs       loss       mae  batch_size  dropout_value  \\\n0             40  11.457275  2.374314           2            0.1   \n1             80  11.027953  2.529704           2            0.1   \n2             40  18.879210  3.145980           2            0.1   \n3             10  21.524335  3.074557           2            0.1   \n4             80   6.054606  1.890788           2            0.1   \n5             20  12.424296  2.593658           2            0.1   \n6             10  36.311936  4.087215           2            0.1   \n7             80  27.776842  3.539782           2            0.1   \n8             10  26.009413  3.719249           2            0.1   \n9             20  31.270360  4.182493           2            0.1   \n10            40  19.052405  3.224401           2            0.1   \n11            20  42.669777  4.620929           2            0.1   \n12            40  30.255696  3.886043           2            0.1   \n13            40  12.531081  2.525484           2            0.1   \n14            80   9.520794  2.253250           2            0.1   \n15            10  24.975928  3.562561           2            0.1   \n16            20  21.657184  3.301359           2            0.1   \n17            10  48.006306  5.032784           2            0.1   \n18            40  15.468398  2.732645           2            0.1   \n19            80  17.633397  3.080702           2            0.1   \n20            40   7.270322  1.959916           2            0.1   \n21            80  14.552948  2.778897           2            0.1   \n22            40  36.033970  4.451427           2            0.1   \n23            10  12.690290  2.490475           2            0.1   \n24            20  24.920259  3.447225           2            0.1   \n25            20  28.117104  3.797457           2            0.1   \n26            20   8.732480  2.145207           2            0.1   \n27            80   9.474153  2.218364           2            0.1   \n28            10  56.620400  5.049278           2            0.1   \n29            20  18.340363  2.982116           2            0.1   \n\n    epoch_number  number_of_layers  number_of_neurons optimizer  \n0             40                 2                 32      Adam  \n1             80                 1                 32      Adam  \n2             40                 2                 16      Adam  \n3             10                 2                 32      Adam  \n4             80                 2                 64      Adam  \n5             20                 2                 32      Adam  \n6             10                 1                 32      Adam  \n7             80                 1                  8      Adam  \n8             10                 2                 16      Adam  \n9             20                 1                 16      Adam  \n10            40                 1                 16      Adam  \n11            20                 1                  8      Adam  \n12            40                 2                  8      Adam  \n13            40                 1                 64      Adam  \n14            80                 1                 64      Adam  \n15            10                 1                 64      Adam  \n16            20                 2                 16      Adam  \n17            10                 2                  8      Adam  \n18            40                 1                 32      Adam  \n19            80                 2                  8      Adam  \n20            40                 2                 64      Adam  \n21            80                 2                 16      Adam  \n22            40                 1                  8      Adam  \n23            10                 2                 64      Adam  \n24            20                 1                 32      Adam  \n25            20                 2                  8      Adam  \n26            20                 2                 64      Adam  \n27            80                 2                 32      Adam  \n28            10                 1                 16      Adam  \n29            20                 1                 64      Adam  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>round_epochs</th>\n      <th>loss</th>\n      <th>mae</th>\n      <th>batch_size</th>\n      <th>dropout_value</th>\n      <th>epoch_number</th>\n      <th>number_of_layers</th>\n      <th>number_of_neurons</th>\n      <th>optimizer</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>40</td>\n      <td>11.457275</td>\n      <td>2.374314</td>\n      <td>2</td>\n      <td>0.1</td>\n      <td>40</td>\n      <td>2</td>\n      <td>32</td>\n      <td>Adam</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>80</td>\n      <td>11.027953</td>\n      <td>2.529704</td>\n      <td>2</td>\n      <td>0.1</td>\n      <td>80</td>\n      <td>1</td>\n      <td>32</td>\n      <td>Adam</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>40</td>\n      <td>18.879210</td>\n      <td>3.145980</td>\n      <td>2</td>\n      <td>0.1</td>\n      <td>40</td>\n      <td>2</td>\n      <td>16</td>\n      <td>Adam</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>10</td>\n      <td>21.524335</td>\n      <td>3.074557</td>\n      <td>2</td>\n      <td>0.1</td>\n      <td>10</td>\n      <td>2</td>\n      <td>32</td>\n      <td>Adam</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>80</td>\n      <td>6.054606</td>\n      <td>1.890788</td>\n      <td>2</td>\n      <td>0.1</td>\n      <td>80</td>\n      <td>2</td>\n      <td>64</td>\n      <td>Adam</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>20</td>\n      <td>12.424296</td>\n      <td>2.593658</td>\n      <td>2</td>\n      <td>0.1</td>\n      <td>20</td>\n      <td>2</td>\n      <td>32</td>\n      <td>Adam</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>10</td>\n      <td>36.311936</td>\n      <td>4.087215</td>\n      <td>2</td>\n      <td>0.1</td>\n      <td>10</td>\n      <td>1</td>\n      <td>32</td>\n      <td>Adam</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>80</td>\n      <td>27.776842</td>\n      <td>3.539782</td>\n      <td>2</td>\n      <td>0.1</td>\n      <td>80</td>\n      <td>1</td>\n      <td>8</td>\n      <td>Adam</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>10</td>\n      <td>26.009413</td>\n      <td>3.719249</td>\n      <td>2</td>\n      <td>0.1</td>\n      <td>10</td>\n      <td>2</td>\n      <td>16</td>\n      <td>Adam</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>20</td>\n      <td>31.270360</td>\n      <td>4.182493</td>\n      <td>2</td>\n      <td>0.1</td>\n      <td>20</td>\n      <td>1</td>\n      <td>16</td>\n      <td>Adam</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>40</td>\n      <td>19.052405</td>\n      <td>3.224401</td>\n      <td>2</td>\n      <td>0.1</td>\n      <td>40</td>\n      <td>1</td>\n      <td>16</td>\n      <td>Adam</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>20</td>\n      <td>42.669777</td>\n      <td>4.620929</td>\n      <td>2</td>\n      <td>0.1</td>\n      <td>20</td>\n      <td>1</td>\n      <td>8</td>\n      <td>Adam</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>40</td>\n      <td>30.255696</td>\n      <td>3.886043</td>\n      <td>2</td>\n      <td>0.1</td>\n      <td>40</td>\n      <td>2</td>\n      <td>8</td>\n      <td>Adam</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>40</td>\n      <td>12.531081</td>\n      <td>2.525484</td>\n      <td>2</td>\n      <td>0.1</td>\n      <td>40</td>\n      <td>1</td>\n      <td>64</td>\n      <td>Adam</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>80</td>\n      <td>9.520794</td>\n      <td>2.253250</td>\n      <td>2</td>\n      <td>0.1</td>\n      <td>80</td>\n      <td>1</td>\n      <td>64</td>\n      <td>Adam</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>10</td>\n      <td>24.975928</td>\n      <td>3.562561</td>\n      <td>2</td>\n      <td>0.1</td>\n      <td>10</td>\n      <td>1</td>\n      <td>64</td>\n      <td>Adam</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>20</td>\n      <td>21.657184</td>\n      <td>3.301359</td>\n      <td>2</td>\n      <td>0.1</td>\n      <td>20</td>\n      <td>2</td>\n      <td>16</td>\n      <td>Adam</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>10</td>\n      <td>48.006306</td>\n      <td>5.032784</td>\n      <td>2</td>\n      <td>0.1</td>\n      <td>10</td>\n      <td>2</td>\n      <td>8</td>\n      <td>Adam</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>40</td>\n      <td>15.468398</td>\n      <td>2.732645</td>\n      <td>2</td>\n      <td>0.1</td>\n      <td>40</td>\n      <td>1</td>\n      <td>32</td>\n      <td>Adam</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>80</td>\n      <td>17.633397</td>\n      <td>3.080702</td>\n      <td>2</td>\n      <td>0.1</td>\n      <td>80</td>\n      <td>2</td>\n      <td>8</td>\n      <td>Adam</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>40</td>\n      <td>7.270322</td>\n      <td>1.959916</td>\n      <td>2</td>\n      <td>0.1</td>\n      <td>40</td>\n      <td>2</td>\n      <td>64</td>\n      <td>Adam</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>80</td>\n      <td>14.552948</td>\n      <td>2.778897</td>\n      <td>2</td>\n      <td>0.1</td>\n      <td>80</td>\n      <td>2</td>\n      <td>16</td>\n      <td>Adam</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>40</td>\n      <td>36.033970</td>\n      <td>4.451427</td>\n      <td>2</td>\n      <td>0.1</td>\n      <td>40</td>\n      <td>1</td>\n      <td>8</td>\n      <td>Adam</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>10</td>\n      <td>12.690290</td>\n      <td>2.490475</td>\n      <td>2</td>\n      <td>0.1</td>\n      <td>10</td>\n      <td>2</td>\n      <td>64</td>\n      <td>Adam</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>20</td>\n      <td>24.920259</td>\n      <td>3.447225</td>\n      <td>2</td>\n      <td>0.1</td>\n      <td>20</td>\n      <td>1</td>\n      <td>32</td>\n      <td>Adam</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>20</td>\n      <td>28.117104</td>\n      <td>3.797457</td>\n      <td>2</td>\n      <td>0.1</td>\n      <td>20</td>\n      <td>2</td>\n      <td>8</td>\n      <td>Adam</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>20</td>\n      <td>8.732480</td>\n      <td>2.145207</td>\n      <td>2</td>\n      <td>0.1</td>\n      <td>20</td>\n      <td>2</td>\n      <td>64</td>\n      <td>Adam</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>80</td>\n      <td>9.474153</td>\n      <td>2.218364</td>\n      <td>2</td>\n      <td>0.1</td>\n      <td>80</td>\n      <td>2</td>\n      <td>32</td>\n      <td>Adam</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>10</td>\n      <td>56.620400</td>\n      <td>5.049278</td>\n      <td>2</td>\n      <td>0.1</td>\n      <td>10</td>\n      <td>1</td>\n      <td>16</td>\n      <td>Adam</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>20</td>\n      <td>18.340363</td>\n      <td>2.982116</td>\n      <td>2</td>\n      <td>0.1</td>\n      <td>20</td>\n      <td>1</td>\n      <td>64</td>\n      <td>Adam</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 52
    }
   ],
   "source": [
    "scan_object2.data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Your best results are:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[0.1, 2, 2, 64, 80, 'Adam', 80, 0],\n       [0.1, 2, 2, 64, 40, 'Adam', 40, 1],\n       [0.1, 2, 2, 64, 20, 'Adam', 20, 2]], dtype=object)"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 17
    }
   ],
   "source": [
    "# use Scan object as input\n",
    "analyze_object2 = talos.Analyze(scan_object2)\n",
    "\n",
    "# get the best n=3 paramaters\n",
    "analyze_object2.best_params('mae', ['loss'], n=3, ascending=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "data": {
      "text/plain": "1.890788197517395"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 18
    }
   ],
   "source": [
    "# lowest mae with the parameters from analyze_object2.best_params('mae', ['loss'], n=1, ascending=True)\n",
    "analyze_object2.low('mae')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Deploy close-to-optimal model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating Models with <code>Evaluate()</code> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Models can be evaluated with <code>Evaluate()</code> against a k-fold cross-validation \n",
    "(<code>fold=K</code> specifies the number of repetitions in <code>Evaluate()</code>). \n",
    "Ideally at least 50% of the data, or more if possible, is kept completely out of the <code>Scan</code> process and only exposed into Evaluate once one or more candidate models have been identified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "5.813494976043701"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 23
    }
   ],
   "source": [
    "evaluate_object = talos.Evaluate(scan_object2)\n",
    "\n",
    "# returns a list with 'folds=10' outputs\n",
    "all_mae_results =  evaluate_object.evaluate(test_data, test_targets, folds=10, metric='mae', task='continuous')\n",
    "\n",
    "# this is the average 'mae' that gives an aedequate estimation of our model error (on the test data)\n",
    "np.mean(all_mae_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once a sufficiently performing model have been found, a deployment package can be easily created."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deploying Models with <code>Deploy()</code> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the right model or models have been found, you can create a deployment package with <code>Deploy()</code> which is then easy to transfer to a production or other environment, send via email, or upload to shared remote location. Best model is automatically chosen based on a given metric ('val_acc' by default).\n",
    "\n",
    "The Deploy package is a zip file that consist of: \n",
    "\n",
    "- details of the scan\n",
    "- model weights\n",
    "- model json\n",
    "- results of the experiment\n",
    "- sample of x data\n",
    "- sample of y data\n",
    "\n",
    "The <code>Deploy</code> package can be easily restored with <code>Restore()</code> which is covered in the next section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Deploy package waw_regression_deploy have been saved.\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "# creates a file waw_regression_deploy.zip (\\approx 13 KB) in the local folder \n",
    "# the parameter 'asc' has to be true if lower means better (e.g. loss, mae) but false otherwise (e.g. accuracy)\n",
    "talos.Deploy(scan_object=scan_object2, model_name='waw_regression_deploy', metric='mae', asc=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Restoring Models with <code>Restore()</code>  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "waw_regression = talos.Restore('waw_regression_deploy.zip')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The <code>Restore</code> object now consists of the assets from the Scan object originally associated with the experiment, together with the model that had been picked as 'best'. The model can be immediately used for making prediction, or use in any other other way Keras model objects can be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [
    {
     "data": {
      "text/plain": "{'name': 'sequential_1',\n 'layers': [{'class_name': 'Dense',\n   'config': {'name': 'dense_1',\n    'trainable': True,\n    'batch_input_shape': (None, 13),\n    'dtype': 'float32',\n    'units': 64,\n    'activation': 'relu',\n    'use_bias': True,\n    'kernel_initializer': {'class_name': 'VarianceScaling',\n     'config': {'scale': 1.0,\n      'mode': 'fan_avg',\n      'distribution': 'uniform',\n      'seed': None}},\n    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n    'kernel_regularizer': None,\n    'bias_regularizer': None,\n    'activity_regularizer': None,\n    'kernel_constraint': None,\n    'bias_constraint': None}},\n  {'class_name': 'Dense',\n   'config': {'name': 'dense_2',\n    'trainable': True,\n    'dtype': 'float32',\n    'units': 64,\n    'activation': 'relu',\n    'use_bias': True,\n    'kernel_initializer': {'class_name': 'VarianceScaling',\n     'config': {'scale': 1.0,\n      'mode': 'fan_avg',\n      'distribution': 'uniform',\n      'seed': None}},\n    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n    'kernel_regularizer': None,\n    'bias_regularizer': None,\n    'activity_regularizer': None,\n    'kernel_constraint': None,\n    'bias_constraint': None}},\n  {'class_name': 'Dropout',\n   'config': {'name': 'dropout_1',\n    'trainable': True,\n    'dtype': 'float32',\n    'rate': 0.1,\n    'noise_shape': None,\n    'seed': None}},\n  {'class_name': 'Dense',\n   'config': {'name': 'dense_3',\n    'trainable': True,\n    'dtype': 'float32',\n    'units': 1,\n    'activation': 'linear',\n    'use_bias': True,\n    'kernel_initializer': {'class_name': 'VarianceScaling',\n     'config': {'scale': 1.0,\n      'mode': 'fan_avg',\n      'distribution': 'uniform',\n      'seed': None}},\n    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n    'kernel_regularizer': None,\n    'bias_regularizer': None,\n    'activity_regularizer': None,\n    'kernel_constraint': None,\n    'bias_constraint': None}}]}"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 59
    }
   ],
   "source": [
    "# What is the 'best' model that we use for predictions?\n",
    "# this should be the same model as in \n",
    "# 'analyze_object2.best_params('mae', ['loss'], n=1, ascending=True)' from the previous cell \n",
    "waw_regression.model.get_config()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "array([[ 8.197606 ],\n       [20.49187  ],\n       [21.705572 ],\n       [33.281807 ],\n       [24.841562 ],\n       [20.987709 ],\n       [25.923063 ],\n       [19.832514 ],\n       [19.9093   ],\n       [24.510082 ],\n       [17.64567  ],\n       [18.076717 ],\n       [15.686621 ],\n       [41.736397 ],\n       [20.328083 ],\n       [20.224676 ],\n       [25.171272 ],\n       [18.35801  ],\n       [21.267384 ],\n       [24.090937 ],\n       [13.295918 ],\n       [13.419363 ],\n       [21.448696 ],\n       [15.651767 ],\n       [18.619667 ],\n       [28.453379 ],\n       [30.033508 ],\n       [30.809359 ],\n       [11.596068 ],\n       [19.085573 ],\n       [19.672104 ],\n       [14.941357 ],\n       [31.070314 ],\n       [24.013067 ],\n       [17.386688 ],\n       [11.310868 ],\n       [15.532573 ],\n       [20.087654 ],\n       [21.32449  ],\n       [23.703724 ],\n       [30.09648  ],\n       [26.680552 ],\n       [14.10518  ],\n       [42.260494 ],\n       [30.563845 ],\n       [26.099182 ],\n       [27.012655 ],\n       [18.045841 ],\n       [27.594448 ],\n       [21.960508 ],\n       [33.789963 ],\n       [21.256718 ],\n       [12.241979 ],\n       [16.50167  ],\n       [33.889236 ],\n       [26.32044  ],\n       [13.020186 ],\n       [47.52209  ],\n       [32.92597  ],\n       [23.639412 ],\n       [28.991941 ],\n       [16.972786 ],\n       [14.584417 ],\n       [19.601606 ],\n       [22.600563 ],\n       [19.28769  ],\n       [14.8627615],\n       [20.548944 ],\n       [13.221139 ],\n       [ 9.8149185],\n       [25.132849 ],\n       [29.19856  ],\n       [31.650396 ],\n       [14.050417 ],\n       [23.628956 ],\n       [20.231346 ],\n       [18.311155 ],\n       [23.533081 ],\n       [33.60491  ],\n       [12.883079 ],\n       [21.314869 ],\n       [37.564335 ],\n       [16.865126 ],\n       [14.044413 ],\n       [17.088596 ],\n       [19.6275   ],\n       [23.449593 ],\n       [22.256556 ],\n       [22.549942 ],\n       [40.53357  ],\n       [19.918411 ],\n       [18.416971 ],\n       [25.045595 ],\n       [43.314827 ],\n       [33.927616 ],\n       [20.253233 ],\n       [35.505264 ],\n       [53.382393 ],\n       [25.683403 ],\n       [49.873863 ],\n       [32.068497 ],\n       [23.607462 ]], dtype=float32)"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 60
    }
   ],
   "source": [
    "# make predictions with the model\n",
    "# if you are interested, compare the output with the ground truth 'test_targets'\n",
    "waw_regression.model.predict(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition, for book keeping purpose, and for simplicity of sharing models with team members and other stakeholders, various attributes are included in the <code>Restore</code> object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "                     0                    1\n0      experiment_name  find_optimal_params\n1        random_method     uniform_mersenne\n2     reduction_method                  NaN\n3   reduction_interval                   50\n4     reduction_window                   20\n5  reduction_threshold                  0.2\n6     reduction_metric              val_acc\n7        complete_time       11/19/19/11:09\n8              x_shape            (404, 13)\n9              y_shape               (404,)",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>experiment_name</td>\n      <td>find_optimal_params</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>random_method</td>\n      <td>uniform_mersenne</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>reduction_method</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>reduction_interval</td>\n      <td>50</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>reduction_window</td>\n      <td>20</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>reduction_threshold</td>\n      <td>0.2</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>reduction_metric</td>\n      <td>val_acc</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>complete_time</td>\n      <td>11/19/19/11:09</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>x_shape</td>\n      <td>(404, 13)</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>y_shape</td>\n      <td>(404,)</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 29
    }
   ],
   "source": [
    "# get the meta-data for the experiment\n",
    "waw_regression.details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "{'number_of_layers': [1, 2],\n 'number_of_neurons': [8, 16, 32, 64],\n 'epoch_number': [10, 20, 40, 80],\n 'dropout_value': [0.1],\n 'optimizer': ['Adam'],\n 'batch_size': [2]}"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 31
    }
   ],
   "source": [
    "# get the hyperparameter space boundary, these are the hyperparameter values that you have considered before\n",
    "waw_regression.params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "    round_epochs       loss       mae  batch_size  dropout_value  \\\n0             40  11.457275  2.374314           2            0.1   \n1             80  11.027953  2.529704           2            0.1   \n2             40  18.879210  3.145980           2            0.1   \n3             10  21.524335  3.074557           2            0.1   \n4             80   6.054606  1.890788           2            0.1   \n5             20  12.424296  2.593658           2            0.1   \n6             10  36.311936  4.087215           2            0.1   \n7             80  27.776842  3.539782           2            0.1   \n8             10  26.009413  3.719249           2            0.1   \n9             20  31.270360  4.182493           2            0.1   \n10            40  19.052405  3.224401           2            0.1   \n11            20  42.669777  4.620929           2            0.1   \n12            40  30.255696  3.886043           2            0.1   \n13            40  12.531081  2.525484           2            0.1   \n14            80   9.520794  2.253250           2            0.1   \n15            10  24.975928  3.562561           2            0.1   \n16            20  21.657184  3.301359           2            0.1   \n17            10  48.006306  5.032784           2            0.1   \n18            40  15.468398  2.732645           2            0.1   \n19            80  17.633397  3.080702           2            0.1   \n20            40   7.270322  1.959916           2            0.1   \n21            80  14.552948  2.778897           2            0.1   \n22            40  36.033970  4.451427           2            0.1   \n23            10  12.690290  2.490475           2            0.1   \n24            20  24.920259  3.447225           2            0.1   \n25            20  28.117104  3.797457           2            0.1   \n26            20   8.732480  2.145207           2            0.1   \n27            80   9.474153  2.218364           2            0.1   \n28            10  56.620400  5.049278           2            0.1   \n29            20  18.340363  2.982116           2            0.1   \n\n    epoch_number  number_of_layers  number_of_neurons optimizer  \n0             40                 2                 32      Adam  \n1             80                 1                 32      Adam  \n2             40                 2                 16      Adam  \n3             10                 2                 32      Adam  \n4             80                 2                 64      Adam  \n5             20                 2                 32      Adam  \n6             10                 1                 32      Adam  \n7             80                 1                  8      Adam  \n8             10                 2                 16      Adam  \n9             20                 1                 16      Adam  \n10            40                 1                 16      Adam  \n11            20                 1                  8      Adam  \n12            40                 2                  8      Adam  \n13            40                 1                 64      Adam  \n14            80                 1                 64      Adam  \n15            10                 1                 64      Adam  \n16            20                 2                 16      Adam  \n17            10                 2                  8      Adam  \n18            40                 1                 32      Adam  \n19            80                 2                  8      Adam  \n20            40                 2                 64      Adam  \n21            80                 2                 16      Adam  \n22            40                 1                  8      Adam  \n23            10                 2                 64      Adam  \n24            20                 1                 32      Adam  \n25            20                 2                  8      Adam  \n26            20                 2                 64      Adam  \n27            80                 2                 32      Adam  \n28            10                 1                 16      Adam  \n29            20                 1                 64      Adam  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>round_epochs</th>\n      <th>loss</th>\n      <th>mae</th>\n      <th>batch_size</th>\n      <th>dropout_value</th>\n      <th>epoch_number</th>\n      <th>number_of_layers</th>\n      <th>number_of_neurons</th>\n      <th>optimizer</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>40</td>\n      <td>11.457275</td>\n      <td>2.374314</td>\n      <td>2</td>\n      <td>0.1</td>\n      <td>40</td>\n      <td>2</td>\n      <td>32</td>\n      <td>Adam</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>80</td>\n      <td>11.027953</td>\n      <td>2.529704</td>\n      <td>2</td>\n      <td>0.1</td>\n      <td>80</td>\n      <td>1</td>\n      <td>32</td>\n      <td>Adam</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>40</td>\n      <td>18.879210</td>\n      <td>3.145980</td>\n      <td>2</td>\n      <td>0.1</td>\n      <td>40</td>\n      <td>2</td>\n      <td>16</td>\n      <td>Adam</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>10</td>\n      <td>21.524335</td>\n      <td>3.074557</td>\n      <td>2</td>\n      <td>0.1</td>\n      <td>10</td>\n      <td>2</td>\n      <td>32</td>\n      <td>Adam</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>80</td>\n      <td>6.054606</td>\n      <td>1.890788</td>\n      <td>2</td>\n      <td>0.1</td>\n      <td>80</td>\n      <td>2</td>\n      <td>64</td>\n      <td>Adam</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>20</td>\n      <td>12.424296</td>\n      <td>2.593658</td>\n      <td>2</td>\n      <td>0.1</td>\n      <td>20</td>\n      <td>2</td>\n      <td>32</td>\n      <td>Adam</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>10</td>\n      <td>36.311936</td>\n      <td>4.087215</td>\n      <td>2</td>\n      <td>0.1</td>\n      <td>10</td>\n      <td>1</td>\n      <td>32</td>\n      <td>Adam</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>80</td>\n      <td>27.776842</td>\n      <td>3.539782</td>\n      <td>2</td>\n      <td>0.1</td>\n      <td>80</td>\n      <td>1</td>\n      <td>8</td>\n      <td>Adam</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>10</td>\n      <td>26.009413</td>\n      <td>3.719249</td>\n      <td>2</td>\n      <td>0.1</td>\n      <td>10</td>\n      <td>2</td>\n      <td>16</td>\n      <td>Adam</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>20</td>\n      <td>31.270360</td>\n      <td>4.182493</td>\n      <td>2</td>\n      <td>0.1</td>\n      <td>20</td>\n      <td>1</td>\n      <td>16</td>\n      <td>Adam</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>40</td>\n      <td>19.052405</td>\n      <td>3.224401</td>\n      <td>2</td>\n      <td>0.1</td>\n      <td>40</td>\n      <td>1</td>\n      <td>16</td>\n      <td>Adam</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>20</td>\n      <td>42.669777</td>\n      <td>4.620929</td>\n      <td>2</td>\n      <td>0.1</td>\n      <td>20</td>\n      <td>1</td>\n      <td>8</td>\n      <td>Adam</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>40</td>\n      <td>30.255696</td>\n      <td>3.886043</td>\n      <td>2</td>\n      <td>0.1</td>\n      <td>40</td>\n      <td>2</td>\n      <td>8</td>\n      <td>Adam</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>40</td>\n      <td>12.531081</td>\n      <td>2.525484</td>\n      <td>2</td>\n      <td>0.1</td>\n      <td>40</td>\n      <td>1</td>\n      <td>64</td>\n      <td>Adam</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>80</td>\n      <td>9.520794</td>\n      <td>2.253250</td>\n      <td>2</td>\n      <td>0.1</td>\n      <td>80</td>\n      <td>1</td>\n      <td>64</td>\n      <td>Adam</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>10</td>\n      <td>24.975928</td>\n      <td>3.562561</td>\n      <td>2</td>\n      <td>0.1</td>\n      <td>10</td>\n      <td>1</td>\n      <td>64</td>\n      <td>Adam</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>20</td>\n      <td>21.657184</td>\n      <td>3.301359</td>\n      <td>2</td>\n      <td>0.1</td>\n      <td>20</td>\n      <td>2</td>\n      <td>16</td>\n      <td>Adam</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>10</td>\n      <td>48.006306</td>\n      <td>5.032784</td>\n      <td>2</td>\n      <td>0.1</td>\n      <td>10</td>\n      <td>2</td>\n      <td>8</td>\n      <td>Adam</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>40</td>\n      <td>15.468398</td>\n      <td>2.732645</td>\n      <td>2</td>\n      <td>0.1</td>\n      <td>40</td>\n      <td>1</td>\n      <td>32</td>\n      <td>Adam</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>80</td>\n      <td>17.633397</td>\n      <td>3.080702</td>\n      <td>2</td>\n      <td>0.1</td>\n      <td>80</td>\n      <td>2</td>\n      <td>8</td>\n      <td>Adam</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>40</td>\n      <td>7.270322</td>\n      <td>1.959916</td>\n      <td>2</td>\n      <td>0.1</td>\n      <td>40</td>\n      <td>2</td>\n      <td>64</td>\n      <td>Adam</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>80</td>\n      <td>14.552948</td>\n      <td>2.778897</td>\n      <td>2</td>\n      <td>0.1</td>\n      <td>80</td>\n      <td>2</td>\n      <td>16</td>\n      <td>Adam</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>40</td>\n      <td>36.033970</td>\n      <td>4.451427</td>\n      <td>2</td>\n      <td>0.1</td>\n      <td>40</td>\n      <td>1</td>\n      <td>8</td>\n      <td>Adam</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>10</td>\n      <td>12.690290</td>\n      <td>2.490475</td>\n      <td>2</td>\n      <td>0.1</td>\n      <td>10</td>\n      <td>2</td>\n      <td>64</td>\n      <td>Adam</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>20</td>\n      <td>24.920259</td>\n      <td>3.447225</td>\n      <td>2</td>\n      <td>0.1</td>\n      <td>20</td>\n      <td>1</td>\n      <td>32</td>\n      <td>Adam</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>20</td>\n      <td>28.117104</td>\n      <td>3.797457</td>\n      <td>2</td>\n      <td>0.1</td>\n      <td>20</td>\n      <td>2</td>\n      <td>8</td>\n      <td>Adam</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>20</td>\n      <td>8.732480</td>\n      <td>2.145207</td>\n      <td>2</td>\n      <td>0.1</td>\n      <td>20</td>\n      <td>2</td>\n      <td>64</td>\n      <td>Adam</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>80</td>\n      <td>9.474153</td>\n      <td>2.218364</td>\n      <td>2</td>\n      <td>0.1</td>\n      <td>80</td>\n      <td>2</td>\n      <td>32</td>\n      <td>Adam</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>10</td>\n      <td>56.620400</td>\n      <td>5.049278</td>\n      <td>2</td>\n      <td>0.1</td>\n      <td>10</td>\n      <td>1</td>\n      <td>16</td>\n      <td>Adam</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>20</td>\n      <td>18.340363</td>\n      <td>2.982116</td>\n      <td>2</td>\n      <td>0.1</td>\n      <td>20</td>\n      <td>1</td>\n      <td>64</td>\n      <td>Adam</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 62
    }
   ],
   "source": [
    "# these are the results from the different runs of Scan()\n",
    "waw_regression.results"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "That's all on Talos for today. Of course, there are several other routines that are provided by Talos. You find\n",
    "the most recent version on GitHub (https://github.com/autonomio/talos).  "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final comments on hyperparameter optimization:\n",
    "\n",
    "* Hyperparameter optimization (at least as described in this tutorial) is an iterative process. You define the\n",
    "hyperparamter boundaries and start a search (with <code>Scan()</code>). Using the results, you define new\n",
    "hyperparameter boundaries and a second search, ...\n",
    "* It is important to determine those hyperparameter that have the largest influence on your performance\n",
    "metric. Talos routine such as <code>correlatie()</code> assist you to find these hyperparameters.\n",
    "* All different hyperparameter combinations are evaluated on a validation set. As usual, your final (after several iterations)\n",
    "model is evaluated with a test set that is independet of the validation set.\n",
    "* Even though Talos can be used analyze to thousand of hyperparameter configurations it is important to\n",
    "first have some kind of intuition which model architecture might be adequate (e.g. do you require \n",
    "fully connected neural networks, convolutional neural networks, what might be the rough number\n",
    "of hidden layers?). Otherwise, since the hyperparameter space grows exponentially you will not be able \n",
    "to evaluate a relevant subset within a reasonable amount of time.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thank you for your participiation! <br>\n",
    "We hope that you have enjoyed this tutorial.\n",
    "\n",
    "Best regards, <br>\n",
    "Charlotte Debus <br>\n",
    "Alexander Rüttgers"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}